{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Retrieve and Clean\n",
    "\n",
    "### This file can be run with \"run all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "1. [Legacy Store Details](#legacy-store-details)\n",
    "1. [Legacy Users](#legacy-users)\n",
    "1. [Orders Table](#orders-table)\n",
    "1. [Card Details](#card-details)\n",
    "1. [Store Details](#store-details)\n",
    "1. [Products Data](#products-data)\n",
    "1. [Date Events Data](#date-events-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALLWAYS RUN FIRST\n",
    "\n",
    "from database_utils import DatabaseConnector\n",
    "from data_extraction import DataExtraction\n",
    "from data_cleaning import DataCleaning\n",
    "import pandas as pd\n",
    "\n",
    "database_connector = DatabaseConnector()\n",
    "data_extractor = DataExtraction()\n",
    "data_cleaner = DataCleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_connector.list_db_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legacy Store Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 451 entries, 1 to 450\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   address        451 non-null    object\n",
      " 1   longitude      451 non-null    object\n",
      " 2   lat            11 non-null     object\n",
      " 3   locality       451 non-null    object\n",
      " 4   store_code     451 non-null    object\n",
      " 5   staff_numbers  451 non-null    object\n",
      " 6   opening_date   451 non-null    object\n",
      " 7   store_type     451 non-null    object\n",
      " 8   latitude       450 non-null    object\n",
      " 9   country_code   451 non-null    object\n",
      " 10  continent      451 non-null    object\n",
      "dtypes: object(11)\n",
      "memory usage: 42.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['address', 'longitude', 'lat', 'locality', 'store_code',\n",
       "       'staff_numbers', 'opening_date', 'store_type', 'latitude',\n",
       "       'country_code', 'continent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reads a database table as \"legacy_store_details_df\" and saves it as a csv\n",
    "legacy_store_details_df = data_extractor.read_rds_table(\"legacy_store_details\")\n",
    "legacy_store_details_df.to_csv(\"original_dfs/original_legacy_store_details_df.csv\")\n",
    "\n",
    "# Prints details of the \"legacy_store_details_df\"\n",
    "legacy_store_details_df.info()\n",
    "legacy_store_details_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'legacy_store_details_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Solen\\Adam's Ai-Core Files\\multinational-retail-data-centralisation103\\main.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Solen/Adam%27s%20Ai-Core%20Files/multinational-retail-data-centralisation103/main.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Prints details of the \"legacy_store_details_df\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Solen/Adam%27s%20Ai-Core%20Files/multinational-retail-data-centralisation103/main.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m legacy_store_details_df\u001b[39m.\u001b[39minfo()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Solen/Adam%27s%20Ai-Core%20Files/multinational-retail-data-centralisation103/main.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m legacy_store_details_df\u001b[39m.\u001b[39mcolumns\n",
      "\u001b[1;31mNameError\u001b[0m: name 'legacy_store_details_df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 441 entries, 1 to 450\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   address        441 non-null    object        \n",
      " 1   longitude      441 non-null    object        \n",
      " 2   latitude       440 non-null    object        \n",
      " 3   locality       441 non-null    object        \n",
      " 4   store_code     441 non-null    object        \n",
      " 5   staff_numbers  441 non-null    object        \n",
      " 6   opening_date   441 non-null    datetime64[ns]\n",
      " 7   store_type     441 non-null    object        \n",
      " 8   country_code   441 non-null    object        \n",
      " 9   continent      441 non-null    object        \n",
      "dtypes: datetime64[ns](1), object(9)\n",
      "memory usage: 37.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Cleans the legacy_store_details_data\n",
    "cleaned_legacy_store_details_df = legacy_store_details_df\n",
    "cleaned_legacy_store_details_df = cleaned_legacy_store_details_df.drop(\"lat\", axis=1)\n",
    "cleaned_legacy_store_details_df = data_cleaner.clean_null(cleaned_legacy_store_details_df)\n",
    "cleaned_legacy_store_details_df = cleaned_legacy_store_details_df[['address', 'longitude', 'latitude', 'locality', 'store_code', 'staff_numbers', 'opening_date', 'store_type', 'country_code', 'continent']]\n",
    "cleaned_legacy_store_details_df = data_cleaner.clean_rows_by_length_condition(cleaned_legacy_store_details_df, \"country_code\", 3)\n",
    "cleaned_legacy_store_details_df = data_cleaner.clean_convert_date_column(cleaned_legacy_store_details_df, \"opening_date\")\n",
    "cleaned_legacy_store_details_df = data_cleaner.clean_replace_value_in_column(cleaned_legacy_store_details_df, \"continent\", \"eeAmerica\", \"America\")\n",
    "cleaned_legacy_store_details_df = data_cleaner.clean_replace_value_in_column(cleaned_legacy_store_details_df, \"continent\", \"eeEurope\", \"Europe\")\n",
    "\n",
    "cleaned_legacy_store_details_df.info()\n",
    "cleaned_legacy_store_details_df.to_csv(\"cleaned_dfs/cleaned_legacy_store_details_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legacy Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15320 entries, 0 to 1249\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   first_name     15320 non-null  object\n",
      " 1   last_name      15320 non-null  object\n",
      " 2   date_of_birth  15320 non-null  object\n",
      " 3   company        15320 non-null  object\n",
      " 4   email_address  15320 non-null  object\n",
      " 5   address        15320 non-null  object\n",
      " 6   country        15320 non-null  object\n",
      " 7   country_code   15320 non-null  object\n",
      " 8   phone_number   15320 non-null  object\n",
      " 9   join_date      15320 non-null  object\n",
      " 10  user_uuid      15320 non-null  object\n",
      "dtypes: object(11)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['first_name', 'last_name', 'date_of_birth', 'company', 'email_address',\n",
       "       'address', 'country', 'country_code', 'phone_number', 'join_date',\n",
       "       'user_uuid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reads a database table as \"legacy_users_df\" and saves it as a csv\n",
    "legacy_users_df = data_extractor.read_rds_table(\"legacy_users\")\n",
    "legacy_users_df.to_csv(\"original_dfs/original_legacy_users_df.csv\")\n",
    "\n",
    "# Prints details of the \"legacy_users_df\"\n",
    "legacy_users_df.info()\n",
    "legacy_users_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15284 entries, 0 to 1249\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   first_name     15284 non-null  object        \n",
      " 1   last_name      15284 non-null  object        \n",
      " 2   date_of_birth  15284 non-null  datetime64[ns]\n",
      " 3   company        15284 non-null  object        \n",
      " 4   email_address  15284 non-null  object        \n",
      " 5   address        15284 non-null  object        \n",
      " 6   country        15284 non-null  object        \n",
      " 7   country_code   15284 non-null  object        \n",
      " 8   phone_number   15284 non-null  object        \n",
      " 9   join_date      15284 non-null  datetime64[ns]\n",
      " 10  user_uuid      15284 non-null  object        \n",
      "dtypes: datetime64[ns](2), object(9)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Table 'dim_users' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Solen\\Adam's Ai-Core Files\\multinational-retail-data-centralisation103\\main.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Solen/Adam%27s%20Ai-Core%20Files/multinational-retail-data-centralisation103/main.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m cleaned_legacy_users_df\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mcleaned_dfs/cleaned_legacy_users_df.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Solen/Adam%27s%20Ai-Core%20Files/multinational-retail-data-centralisation103/main.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Uploads to sales_data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Solen/Adam%27s%20Ai-Core%20Files/multinational-retail-data-centralisation103/main.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m database_connector\u001b[39m.\u001b[39;49mupload_to_db(cleaned_legacy_users_df, \u001b[39m\"\u001b[39;49m\u001b[39mdim_users\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Solen\\Adam's Ai-Core Files\\multinational-retail-data-centralisation103\\database_utils.py:39\u001b[0m, in \u001b[0;36mDatabaseConnector.upload_to_db\u001b[1;34m(self, df, table_name)\u001b[0m\n\u001b[0;32m     37\u001b[0m db_url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpostgresql+psycopg2://\u001b[39m\u001b[39m{\u001b[39;00mcreds[\u001b[39m'\u001b[39m\u001b[39msales_data_USER\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00mcreds[\u001b[39m'\u001b[39m\u001b[39msales_data_PASSWORD\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m@\u001b[39m\u001b[39m{\u001b[39;00mcreds[\u001b[39m'\u001b[39m\u001b[39msales_data_HOST\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00mcreds[\u001b[39m'\u001b[39m\u001b[39msales_data_PORT\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mcreds[\u001b[39m'\u001b[39m\u001b[39msales_data_DATABASE\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m engine \u001b[39m=\u001b[39m create_engine(db_url)\n\u001b[1;32m---> 39\u001b[0m df\u001b[39m.\u001b[39;49mto_sql(table_name, engine)\n",
      "File \u001b[1;32mc:\\Users\\Solen\\Miniconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Solen\\Miniconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3008\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2813\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2814\u001b[0m \u001b[39mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2815\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3004\u001b[0m \u001b[39m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   3005\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[0;32m   3006\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m sql\n\u001b[1;32m-> 3008\u001b[0m \u001b[39mreturn\u001b[39;00m sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[0;32m   3009\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3010\u001b[0m     name,\n\u001b[0;32m   3011\u001b[0m     con,\n\u001b[0;32m   3012\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[0;32m   3013\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[0;32m   3014\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   3015\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3016\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3017\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   3018\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m   3019\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Solen\\Miniconda3\\Lib\\site-packages\\pandas\\io\\sql.py:788\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    784\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument should be either a Series or a DataFrame\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    785\u001b[0m     )\n\u001b[0;32m    787\u001b[0m \u001b[39mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[39m=\u001b[39mschema, need_transaction\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 788\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[0;32m    789\u001b[0m         frame,\n\u001b[0;32m    790\u001b[0m         name,\n\u001b[0;32m    791\u001b[0m         if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[0;32m    792\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m    793\u001b[0m         index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m    794\u001b[0m         schema\u001b[39m=\u001b[39;49mschema,\n\u001b[0;32m    795\u001b[0m         chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m    796\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    797\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m    798\u001b[0m         engine\u001b[39m=\u001b[39;49mengine,\n\u001b[0;32m    799\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mengine_kwargs,\n\u001b[0;32m    800\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Solen\\Miniconda3\\Lib\\site-packages\\pandas\\io\\sql.py:1948\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1898\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1899\u001b[0m \u001b[39mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   1900\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1944\u001b[0m \u001b[39m    Any additional kwargs are passed to the engine.\u001b[39;00m\n\u001b[0;32m   1945\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1946\u001b[0m sql_engine \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[1;32m-> 1948\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprep_table(\n\u001b[0;32m   1949\u001b[0m     frame\u001b[39m=\u001b[39;49mframe,\n\u001b[0;32m   1950\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   1951\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[0;32m   1952\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   1953\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   1954\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[0;32m   1955\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1956\u001b[0m )\n\u001b[0;32m   1958\u001b[0m total_inserted \u001b[39m=\u001b[39m sql_engine\u001b[39m.\u001b[39minsert_records(\n\u001b[0;32m   1959\u001b[0m     table\u001b[39m=\u001b[39mtable,\n\u001b[0;32m   1960\u001b[0m     con\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcon,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1967\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mengine_kwargs,\n\u001b[0;32m   1968\u001b[0m )\n\u001b[0;32m   1970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_case_sensitive(name\u001b[39m=\u001b[39mname, schema\u001b[39m=\u001b[39mschema)\n",
      "File \u001b[1;32mc:\\Users\\Solen\\Miniconda3\\Lib\\site-packages\\pandas\\io\\sql.py:1852\u001b[0m, in \u001b[0;36mSQLDatabase.prep_table\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, dtype)\u001b[0m\n\u001b[0;32m   1840\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe type of \u001b[39m\u001b[39m{\u001b[39;00mcol\u001b[39m}\u001b[39;00m\u001b[39m is not a SQLAlchemy type\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1842\u001b[0m table \u001b[39m=\u001b[39m SQLTable(\n\u001b[0;32m   1843\u001b[0m     name,\n\u001b[0;32m   1844\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1850\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   1851\u001b[0m )\n\u001b[1;32m-> 1852\u001b[0m table\u001b[39m.\u001b[39;49mcreate()\n\u001b[0;32m   1853\u001b[0m \u001b[39mreturn\u001b[39;00m table\n",
      "File \u001b[1;32mc:\\Users\\Solen\\Miniconda3\\Lib\\site-packages\\pandas\\io\\sql.py:927\u001b[0m, in \u001b[0;36mSQLTable.create\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    925\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexists():\n\u001b[0;32m    926\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mif_exists \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfail\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 927\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTable \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m already exists.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    928\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mif_exists \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mreplace\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    929\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpd_sql\u001b[39m.\u001b[39mdrop_table(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mschema)\n",
      "\u001b[1;31mValueError\u001b[0m: Table 'dim_users' already exists."
     ]
    }
   ],
   "source": [
    "# Starts a new cleaned variable\n",
    "cleaned_legacy_users_df = legacy_users_df\n",
    "\n",
    "# Cleans the legacy_users_data\n",
    "cleaned_legacy_users_df = data_cleaner.clean_rows_by_length_condition(cleaned_legacy_users_df, \"country_code\", 3)\n",
    "cleaned_legacy_users_df = data_cleaner.clean_null(cleaned_legacy_users_df)\n",
    "cleaned_legacy_users_df = data_cleaner.clean_replace_value_in_column(cleaned_legacy_users_df, \"country_code\", \"GGB\", \"GB\")\n",
    "cleaned_legacy_users_df = data_cleaner.clean_convert_date_column(cleaned_legacy_users_df, \"date_of_birth\")\n",
    "cleaned_legacy_users_df = data_cleaner.clean_convert_date_column(cleaned_legacy_users_df, \"join_date\")\n",
    "# cleaned_legacy_users_df = cleaned_legacy_users_df.reset_index(drop=True)    # Resets the index\n",
    "\n",
    "cleaned_legacy_users_df.info()\n",
    "\n",
    "# Overwrites the cleaned_df.csv witht the current cleared_df \n",
    "cleaned_legacy_users_df.to_csv(\"cleaned_dfs/cleaned_legacy_users_df.csv\")\n",
    "\n",
    "# Uploads to sales_data\n",
    "database_connector.upload_to_db(cleaned_legacy_users_df, \"dim_users\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orders Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 120123 entries, 0 to 118804\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   level_0           120123 non-null  int64 \n",
      " 1   date_uuid         120123 non-null  object\n",
      " 2   first_name        15284 non-null   object\n",
      " 3   last_name         15284 non-null   object\n",
      " 4   user_uuid         120123 non-null  object\n",
      " 5   card_number       120123 non-null  int64 \n",
      " 6   store_code        120123 non-null  object\n",
      " 7   product_code      120123 non-null  object\n",
      " 8   1                 0 non-null       object\n",
      " 9   product_quantity  120123 non-null  int64 \n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 10.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['level_0', 'date_uuid', 'first_name', 'last_name', 'user_uuid',\n",
       "       'card_number', 'store_code', 'product_code', '1', 'product_quantity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reads a database table as \"orders_table_df\" and saves it as a csv\n",
    "orders_table_df = data_extractor.read_rds_table(\"orders_table\")\n",
    "orders_table_df.to_csv(\"original_dfs/original_orders_table_df.csv\")\n",
    "\n",
    "# Prints details of the \"orders_table_df\"\n",
    "orders_table_df.info()\n",
    "orders_table_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 120123 entries, 0 to 118804\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   date_uuid         120123 non-null  object\n",
      " 1   user_uuid         120123 non-null  object\n",
      " 2   card_number       120123 non-null  int64 \n",
      " 3   store_code        120123 non-null  object\n",
      " 4   product_code      120123 non-null  object\n",
      " 5   product_quantity  120123 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Starts a new cleaned variable\n",
    "cleaned_orders_table_df = orders_table_df\n",
    "\n",
    "# Cleans the orders_table_df\n",
    "cleaned_orders_table_df = cleaned_orders_table_df.drop([\"level_0\", \"1\", \"first_name\", \"last_name\"], axis=1)\n",
    "\n",
    "cleaned_orders_table_df.info()\n",
    "\n",
    "# Overwrites the cleaned_df.csv witht the current cleared_df \n",
    "cleaned_orders_table_df.to_csv(\"cleaned_dfs/cleaned_orders_table_df.csv\")\n",
    "\n",
    "# Uploads to sales_data\n",
    "# database_connector.upload_to_db(cleaned_orders_table_df, \"orders_table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Card Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15309 entries, 0 to 15308\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   card_number             15309 non-null  object\n",
      " 1   expiry_date             15309 non-null  object\n",
      " 2   card_provider           15309 non-null  object\n",
      " 3   date_payment_confirmed  15309 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 478.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['card_number', 'expiry_date', 'card_provider',\n",
       "       'date_payment_confirmed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve data from pdf and save to pdf\n",
    "card_details_df = data_extractor.retrieve_pdf_data("https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf")\n",
    "card_details_df.to_csv(\"original_dfs/original_card_details.csv\")\n",
    "\n",
    "# Prints details of the \"card_details_df\"\n",
    "card_details_df.info()\n",
    "card_details_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15284 entries, 0 to 15308\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   card_number             15284 non-null  object        \n",
      " 1   expiry_date             15284 non-null  datetime64[ns]\n",
      " 2   card_provider           15284 non-null  object        \n",
      " 3   date_payment_confirmed  15284 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), object(2)\n",
      "memory usage: 597.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Starts a new cleaned variable\n",
    "cleaned_card_details_df = card_details_df\n",
    "\n",
    "# Cleans the \"card_details_df\"\n",
    "cleaned_card_details_df = data_cleaner.clean_null(cleaned_card_details_df)\n",
    "cleaned_card_details_df[\"card_number\"] = cleaned_card_details_df[\"card_number\"].astype(str).str.strip('?')\n",
    "cleaned_card_details_df = data_cleaner.clean_rows_by_length_condition(cleaned_card_details_df, \"expiry_date\", 5)\n",
    "cleaned_card_details_df['expiry_date'] = pd.to_datetime(cleaned_card_details_df['expiry_date'], format='%m/%y')\n",
    "cleaned_card_details_df = data_cleaner.clean_convert_date_column(cleaned_card_details_df, \"date_payment_confirmed\")\n",
    "\n",
    "cleaned_card_details_df.info()\n",
    "\n",
    "# Overwrites the cleaned_df.csv with the current cleared_df \n",
    "cleaned_card_details_df.to_csv(\"cleaned_dfs/cleaned_card_details_df.csv\")\n",
    "\n",
    "# Uploads to sales_data\n",
    "database_connector.upload_to_db(cleaned_card_details_df, \"dim_card_details\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists number of stores in the store data\n",
    "data_extractor.list_number_of_stores()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TAKES 10 MINMUTES!!!!\n",
    "store_data_df = data_extractor.retrieve_stores_data()\n",
    "store_data_df\n",
    "store_data_df.to_csv(\"original_dfs/original_store_data.csv\")\n",
    "\n",
    "# Note: This table appears to be the same as \"legacy_store_details_df\" although I have treated is is if it was not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 441 entries, 0 to 450\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   address        441 non-null    object        \n",
      " 1   longitude      440 non-null    object        \n",
      " 2   latitude       440 non-null    object        \n",
      " 3   locality       441 non-null    object        \n",
      " 4   store_code     441 non-null    object        \n",
      " 5   staff_numbers  441 non-null    object        \n",
      " 6   opening_date   441 non-null    datetime64[ns]\n",
      " 7   store_type     441 non-null    object        \n",
      " 8   country_code   441 non-null    object        \n",
      " 9   continent      441 non-null    object        \n",
      "dtypes: datetime64[ns](1), object(9)\n",
      "memory usage: 37.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Starts a new cleaned variable\n",
    "cleaned_store_data_df = store_data_df\n",
    "\n",
    "# Cleans the store_data_df\n",
    "cleaned_store_data_df = cleaned_store_data_df.drop([\"lat\", \"index\"], axis=1)\n",
    "cleaned_store_data_df = data_cleaner.clean_null(cleaned_store_data_df)\n",
    "cleaned_store_data_df = data_cleaner.clean_replace_value_in_column(cleaned_store_data_df, \"longitude\", \"N/A\", pd.NA)\n",
    "cleaned_store_data_df = cleaned_store_data_df[['address', 'longitude', 'latitude', 'locality', 'store_code', 'staff_numbers', 'opening_date', 'store_type', 'country_code', 'continent']]\n",
    "cleaned_store_data_df = data_cleaner.clean_rows_by_length_condition(cleaned_store_data_df, \"country_code\", 3)\n",
    "cleaned_store_data_df = data_cleaner.clean_convert_date_column(cleaned_store_data_df, \"opening_date\")\n",
    "cleaned_store_data_df = data_cleaner.clean_replace_value_in_column(cleaned_store_data_df, \"continent\", \"eeAmerica\", \"America\")\n",
    "cleaned_store_data_df = data_cleaner.clean_replace_value_in_column(cleaned_store_data_df, \"continent\", \"eeEurope\", \"Europe\")\n",
    "cleaned_store_data_df = data_cleaner.clean_replace_value_in_column(cleaned_store_data_df, \"staff_numbers\", \"30e\", 30)\n",
    "cleaned_store_data_df = data_cleaner.clean_replace_value_in_column(cleaned_store_data_df, \"staff_numbers\", \"A97\", 97)\n",
    "cleaned_store_data_df = data_cleaner.clean_replace_value_in_column(cleaned_store_data_df, \"staff_numbers\", \"80R\", 80)\n",
    "cleaned_store_data_df = data_cleaner.clean_replace_value_in_column(cleaned_store_data_df, \"staff_numbers\", \"J78\", 78)\n",
    "cleaned_store_data_df = data_cleaner.clean_replace_value_in_column(cleaned_store_data_df, \"staff_numbers\", \"3n9\", 39)\n",
    "\n",
    "cleaned_store_data_df.info()\n",
    "cleaned_store_data_df.to_csv(\"cleaned_dfs/cleaned_store_data_df.csv\")\n",
    "\n",
    "# Uploads to sales_data\n",
    "database_connector.upload_to_db(cleaned_store_data_df, \"dim_store_details\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Products Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloads and saves the products data\n",
    "data_extractor.extract_from_s3()\n",
    "\n",
    "# prints details about the products data\n",
    "products_data_df = pd.read_csv(\"original_dfs/original_products.csv\")\n",
    "products_data_df.info()\n",
    "products_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starts a new cleaned variable\n",
    "cleaned_products_data_df = products_data_df\n",
    "\n",
    "# cleans data in products_data_df\n",
    "cleaned_products_data_df = cleaned_products_data_df.drop(\"Unnamed: 0\", axis=1)\n",
    "cleaned_products_data_df = data_cleaner.clean_null(cleaned_products_data_df)\n",
    "cleaned_products_data_df = data_cleaner.clean_rows_by_length_condition(cleaned_products_data_df, \"product_price\", 7)\n",
    "cleaned_products_data_df = data_cleaner.clean_replace_value_in_column(cleaned_products_data_df, \"weight\", \"77g .\", \"77g\")\n",
    "cleaned_products_data_df = data_cleaner.clean_convert_date_column(cleaned_products_data_df, \"date_added\")\n",
    "\n",
    "# Apply the conversion function to the 'Weight' column\n",
    "cleaned_products_data_df['weight_in_kg'] = cleaned_products_data_df['weight'].apply(data_cleaner.convert_product_weight)\n",
    "\n",
    "cleaned_products_data_df.info()\n",
    "cleaned_products_data_df.to_csv(\"cleaned_dfs/cleaned_products_data_df.csv\")\n",
    "\n",
    "# Uploads to sales_data\n",
    "database_connector.upload_to_db(cleaned_products_data_df, \"dim_products\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Events Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads JSON and writes to csv\n",
    "date_events_df = pd.read_json(\"https://data-handling-public.s3.eu-west-1.amazonaws.com/date_details.json\")\n",
    "date_events_df.to_csv(\"original_dfs/original_date_events_df.csv\")\n",
    "\n",
    "# Print details on the \"date_events_df\"\n",
    "date_events_df.info()\n",
    "date_events_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starts a new cleaned variable\n",
    "cleaned_date_events_df = date_events_df\n",
    "\n",
    "# cleans data in date_events_df\n",
    "cleaned_date_events_df = data_cleaner.clean_null(cleaned_date_events_df)\n",
    "cleaned_date_events_df = data_cleaner.clean_rows_by_length_condition(cleaned_date_events_df, \"month\", 3)\n",
    "cleaned_date_events_df = data_cleaner.concatenate_columns(cleaned_date_events_df, \"date\", [\"year\", \"month\", \"day\"], \"-\")\n",
    "cleaned_date_events_df = data_cleaner.concatenate_columns(cleaned_date_events_df, \"datetime\", [\"date\", \"timestamp\"], \" \")\n",
    "cleaned_date_events_df = data_cleaner.clean_convert_date_column(cleaned_date_events_df, \"date\")\n",
    "cleaned_date_events_df = data_cleaner.clean_convert_date_column(cleaned_date_events_df, \"datetime\")\n",
    "\n",
    "cleaned_date_events_df.info()\n",
    "cleaned_date_events_df.to_csv(\"cleaned_dfs/cleaned_date_events_df.csv\")\n",
    "\n",
    "# Uploads to sales_data\n",
    "database_connector.upload_to_db(cleaned_date_events_df, \"dim_date_time\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Clean Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_card_details_df = pd.read_csv(\"cleaned_dfs/cleaned_card_details_df.csv\")\n",
    "# cleaned_date_events_df = pd.read_csv(\"cleaned_dfs/cleaned_date_events_df.csv\")\n",
    "# # cleaned_legacy_store_details_df = pd.read_csv(\"cleaned_dfs/cleaned_legacy_store_details_df.csv\")\n",
    "# cleaned_legacy_users_df = pd.read_csv(\"cleaned_dfs/cleaned_legacy_users_df.csv\")\n",
    "# cleaned_orders_table_df = pd.read_csv(\"cleaned_dfs/cleaned_orders_table_df.csv\")\n",
    "# cleaned_products_data_df = pd.read_csv(\"cleaned_dfs/cleaned_products_data_df.csv\")\n",
    "# cleaned_store_data_df = pd.read_csv(\"cleaned_dfs/cleaned_store_data_df.csv\")\n",
    "\n",
    "# database_connector.upload_to_db(cleaned_card_details_df, \"dim_card_details\")\n",
    "# database_connector.upload_to_db(cleaned_date_events_df, \"dim_date_time\")\n",
    "# database_connector.upload_to_db(cleaned_legacy_users_df, \"dim_users\")\n",
    "# database_connector.upload_to_db(cleaned_orders_table_df, \"orders_table\")\n",
    "# database_connector.upload_to_db(cleaned_products_data_df, \"dim_prducts\")\n",
    "# database_connector.upload_to_db(cleaned_store_data_df, \"dim_store_details\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
